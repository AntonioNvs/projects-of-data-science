{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complexidade.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hz7E8-GpsZIT"
      ],
      "mount_file_id": "1Ara0ltxqdrrr5T04aIMcd86Y4hxtnCan",
      "authorship_tag": "ABX9TyNk4tLNenhpa/Vu0Wop+zhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonioNvs/projects-of-data-science/blob/main/An%C3%A1lise-de-complexidade-de-frases-em-ingl%C3%AAs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOU2FVB2LZl_"
      },
      "source": [
        "# Identificação de complexidade de uma frase\n",
        "##### Aplicação de revisão de inglês\n",
        "\n",
        "\n",
        "O objetivo desse código é explorar, a partir da construção de uma rede neural profunda, a capacidade de análise de complexidade de uma frase em inglês em níveis, classificados como:\n",
        "\n",
        "- 1 - Fácil entendimento\n",
        "- 2 - Médio entendimento\n",
        "- 3 - Difícil entendimento\n",
        "\n",
        "De tal forma, foi utilizado como base de treino frases classificadas previamente por minha pessoa, logo, a complexidade está intrinsicamente ligada ao meu conhecimento próprio atual, posto que algo ser complexo é relativo e depende do indivíduo no momento medido.\n",
        "\n",
        "Assim, o processo será dividido em N etapas:\n",
        "\n",
        "- **Importação dos dados e das bibliotecas**\n",
        "- **Manipulação dos dados**\n",
        "- **Análise exploratória**\n",
        "- **Construção do modelo**\n",
        "- **Treinamento da rede neural**\n",
        "\n",
        "Ademais, ao final, foi feito um segundo modelo, a partir da média de frequência das palavras na frase, segundo um banco de dados pré-definido.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad6oBp6gNbHO"
      },
      "source": [
        "## Importação dos dados e das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQizLOTTNgOi"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import chardet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "BOxxuvJ0OGRy",
        "outputId": "a3b1f497-6627-42e4-c26d-294d0519f9dd"
      },
      "source": [
        "# Operação para identificar qual o tipo de encodificação do arquivo\n",
        "with open('drive/MyDrive/Projetos/English/phrases.csv', 'rb') as f:\n",
        "    result = chardet.detect(f.read())\n",
        "\n",
        "# Lendo os dados e verificando as colunas visualmente\n",
        "data = pd.read_csv('drive/MyDrive/Projetos/English/phrases.csv', encoding=result['encoding'],quotechar='\"')\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>phrase</th>\n",
              "      <th>document_id</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3157</td>\n",
              "      <td>to the environment and climate</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>115</td>\n",
              "      <td>This is not a pipe dream</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98</td>\n",
              "      <td>decades before a large Tesla semitruck.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3833</td>\n",
              "      <td>and understand exactly what motivates them</td>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2220</td>\n",
              "      <td>it sounds really epic.</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                      phrase  document_id  level\n",
              "0  3157              to the environment and climate           10    1.0\n",
              "1   115                    This is not a pipe dream            1    2.0\n",
              "2    98     decades before a large Tesla semitruck.            1    1.0\n",
              "3  3833  and understand exactly what motivates them           11    1.0\n",
              "4  2220                      it sounds really epic.            8    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs4bChtHPuaQ"
      },
      "source": [
        "# Manipulação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XND27r8ET_4V"
      },
      "source": [
        "# Eliminando linhas vazias\n",
        "data = data.dropna()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w2D8TeaPxjn"
      },
      "source": [
        "# Separando as colunas de entrada e saída\n",
        "\n",
        "sentences = data['phrase']\n",
        "labels = data['level']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMl-EUVJnPzg"
      },
      "source": [
        "# Transformando cada nível em uma coluna de classificação\n",
        "labels = pd.get_dummies(labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICcO71SnYHh"
      },
      "source": [
        "# Renomeando as colunas de níveis\n",
        "labels = labels.rename(columns= lambda name: str(int(name)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-v3Ls4Qla2"
      },
      "source": [
        "def processing_text(sen):\n",
        "    # Removendo pontuação\n",
        "    sentence = re.sub(r'[^\\w\\s]', '', sen)\n",
        "\n",
        "    # Removendo caracteres únicos\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removendo múltiplos espaços\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence.lower()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImUIk62gQyhJ"
      },
      "source": [
        "x = []\n",
        "\n",
        "# Adequando as frases a um padrão\n",
        "for sentence in sentences:\n",
        "  x.append(processing_text(sentence))\n",
        "\n",
        "# Separando os valores do label\n",
        "y = labels.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n2VXV6PRU4A"
      },
      "source": [
        "# Análise exploratória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urHiUrGfRenw"
      },
      "source": [
        "### Quantidade de frases de cada nível"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XxaI_v2RRXeH",
        "outputId": "94cf16b9-5015-42b3-89ef-212f00641324"
      },
      "source": [
        "# Soma de cada classificação\n",
        "list_sum_values_levels = labels.value_counts()\n",
        "\n",
        "plt.bar(labels.columns, list_sum_values_levels.values)\n",
        "plt.title('Relação de nível de dificuldade e quantidade')\n",
        "plt.xlabel('Níveis')\n",
        "plt.ylabel('Quantidade')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbrISozWvJy"
      },
      "source": [
        "Um dos tópicos principais dessa análise é ver o nível de dificuldade que a pessoa enfrenta.\n",
        "\n",
        "Percebe-se então a maior quantidade de classificações 'fácil' e 'média', demonstra um inglês intermediário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbLgcRsPXFsN"
      },
      "source": [
        "### Dificuldade de cada palavra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HufDFEBDXIHl",
        "outputId": "c6767b04-58a8-4d3c-97ae-f49bfbce6f3f"
      },
      "source": [
        "# Dicionário de palavras\n",
        "words = {}\n",
        "\n",
        "# Iteração por cada linha\n",
        "for row in data.values:\n",
        "  phrase = row[1]\n",
        "  level = row[3]\n",
        "\n",
        "  # Realizando a média de nível de cada palavra\n",
        "  for word in phrase.split(' '):\n",
        "    try:\n",
        "      words[word] = (words[word] + level) / 2\n",
        "    except KeyError:\n",
        "      words[word] = level\n",
        "\n",
        "# Ordenação decrescente de nível de cada palavra\n",
        "print(sorted(words.items(), reverse=True, key= lambda a: a[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('perhaps', 3.0), ('congestion', 3.0), ('offshore', 3.0), ('wind.', 3.0), ('athletic', 3.0), ('prowess,', 3.0), ('intervene', 3.0), ('statutory', 3.0), ('framework.', 3.0), ('blurry', 3.0), ('image', 3.0), ('determine', 3.0), ('self-taught', 3.0), ('youth', 3.0), ('group', 3.0), ('told', 3.0), ('plans,', 3.0), ('entirely', 3.0), ('mental.', 3.0), ('concern', 3.0), ('razor-sharp', 3.0), ('cutting', 3.0), ('secret', 3.0), ('knobs', 3.0), ('across', 3.0), ('acres', 3.0), ('land', 3.0), ('lifts,', 3.0), ('flooding', 3.0), ('laid', 3.0), ('principles.', 3.0), ('ecological', 3.0), ('retail', 3.0), ('sales', 3.0), ('stores.', 3.0), ('biased', 3.0), ('have,', 3.0), ('acknowledge', 3.0), ('destroyed', 3.0), ('hard', 3.0), ('halfway', 3.0), ('Cybernetics', 3.0), ('argued', 3.0), ('persuasively', 3.0), ('meanwhile', 3.0), ('keep', 3.0), ('cramming', 3.0), ('While', 3.0), ('sudden', 3.0), ('disappearance', 3.0), ('brought', 3.0), ('foisted', 3.0), ('permaculture', 3.0), ('ancient', 3.0), ('plants.', 3.0), ('kosher,', 3.0), ('\"\"Really?', 3.0), ('supernovae.', 3.0), ('Increasing', 3.0), ('crop', 3.0), ('diversity', 3.0), ('crucial', 3.0), ('lights', 3.0), ('came', 3.0), ('blazing', 3.0), ('astronomer', 3.0), ('perched', 3.0), ('repowering', 3.0), ('island', 3.0), ('hopper', 3.0), ('prop', 3.0), ('planes.', 3.0), ('magic', 3.0), ('sauce', 3.0), ('therefore', 3.0), ('coated', 3.0), ('emulsion.', 3.0), ('age', 3.0), ('five', 3.0), ('\"\"Afar\"\"', 3.0), ('extreme.', 3.0), ('biobased', 3.0), ('film', 3.0), ('intercropping', 3.0), ('fields.', 3.0), ('When', 3.0), ('minorities', 3.0), ('undercounted,', 3.0), ('slept', 3.0), ('night,', 3.0), ('terrible', 3.0), ('farmer.', 3.0), ('constant', 3.0), ('willingness', 3.0), ('bake', 3.0), ('freeze', 3.0), ('Bligh', 3.0), ('Street.', 3.0), ('After', 3.0), ('all,', 3.0), ('played', 3.0), ('varsity', 3.0), ('soccer.\"\"', 3.0), ('haul', 3.0), ('trucks', 3.0), ('ships.', 3.0), ('red', 3.0), ('keyslot', 3.0), ('former', 3.0), ('steel', 3.0), ('mill', 3.0), ('Newark,', 3.0), ('New', 3.0), ('Jersey,', 3.0), ('broadcast', 3.0), ('spraying', 3.0), ('chemicals', 3.0), ('becoming', 3.0), ('gatekeeper', 3.0), ('Maybe', 3.0), ('ATM,', 3.0), ('retailer.', 3.0), ('millions', 2.5), ('way,', 2.5), ('enhanced', 2.5), (\"I'd\", 2.5), ('almost', 2.5), ('quite', 2.5), ('carry', 2.5), ('broader', 2.5), ('under', 2.5), (\"You've\", 2.5), ('heard', 2.5), ('undercounted', 2.5), ('cheaper', 2.5), ('backyard', 2.5), ('treatment', 2.5), ('not', 2.4224624633789062), ('within', 2.25), (\"There's\", 2.125), (\"I've\", 2.125), (\"They're\", 2.125), ('she', 2.125), ('an', 2.0772781372070312), ('also', 2.0625), ('They', 2.046875), ('pipe', 2.0), ('dream', 2.0), ('solving', 2.0), ('bend', 2.0), ('Beckham.', 2.0), ('work.', 2.0), ('no', 2.0), ('vaccine', 2.0), ('simply', 2.0), ('applied.', 2.0), ('disaster', 2.0), ('response,', 2.0), ('Hubble', 2.0), ('knew', 2.0), ('rooted', 2.0), ('his', 2.0), ('community,', 2.0), ('walls', 2.0), ('here', 2.0), ('Institute,', 2.0), ('staff', 2.0), ('people,', 2.0), ('As', 2.0), ('part', 2.0), ('Nielsen', 2.0), ('team,', 2.0), ('focus', 2.0), ('sitting', 2.0), ('couches', 2.0), ('become', 2.0), ('corporate', 2.0), ('campuses,', 2.0), ('insurance', 2.0), ('policy', 2.0), ('next', 2.0), ('affected', 2.0), ('asks', 2.0), ('pros', 2.0), ('score', 2.0), ('legislation', 2.0), ('century.', 2.0), ('larger', 2.0), ('aircraft', 2.0), ('mess', 2.0), ('measure', 2.0), ('matters.', 2.0), ('deinvention', 2.0), ('camp', 2.0), ('entrepreneurs', 2.0), ('mimic', 2.0), ('side', 2.0), ('carefully', 2.0), ('designed', 2.0), ('plates', 2.0), ('ways', 2.0), ('strapped', 2.0), (\"what's\", 2.0), ('recipe?', 2.0), ('customers', 2.0), ('began', 2.0), ('say,', 2.0), ('sense', 2.0), ('purpose,', 2.0), ('relationships', 2.0), ('patterns.', 2.0), ('chucked', 2.0), ('American', 2.0), ('farmers.', 2.0), ('but', 2.0), ('Electrifying', 2.0), ('aviation', 2.0), ('solve', 2.0), ('technical', 2.0), ('see,', 2.0), ('put', 2.0), ('possible,', 2.0), ('development', 2.0), ('Ginkgo', 2.0), ('Bioworks', 2.0), ('foundry.', 2.0), ('basis,', 2.0), ('infrastructure', 2.0), ('Reducing', 2.0), ('cash', 2.0), ('economy', 2.0), ('remarkable', 2.0), ('longevity', 2.0), ('electrolysis,', 2.0), ('still', 2.0), ('\"\"Halfcoordinated,\"\"', 2.0), ('limited', 2.0), ('Human', 2.0), ('innovation', 2.0), ('marries', 2.0), ('race,', 2.0), ('employment,', 2.0), ('family', 2.0), ('status,', 2.0), ('requires', 2.0), ('commitment', 2.0), ('foundation', 2.0), ('bottom-up', 2.0), ('generations', 2.0), ('beyond', 2.0), ('there.', 2.0), ('bringing', 2.0), ('Undercounting', 2.0), ('introduce', 2.0), ('bias', 2.0), ('selected', 2.0), ('store', 2.0), ('city', 2.0), ('order', 2.0), ('improve', 2.0), ('lives', 2.0), ('reality', 2.0), ('journey', 2.0), ('us.', 2.0), ('How', 2.0), ('pieces', 2.0), ('path', 2.0), ('establish', 2.0), ('appeared,', 2.0), ('markets', 2.0), ('happen.', 2.0), (\"doesn't\", 2.0), ('involve', 2.0), ('justice.', 2.0), ('world.', 2.0), ('areas', 2.0), ('equity.', 2.0), ('march', 2.0), ('fields', 2.0), ('must', 2.0), ('apply', 2.0), ('best', 2.0), ('political', 2.0), ('unrest.', 2.0), ('transferring', 2.0), ('Our', 2.0), ('includes', 2.0), ('anthropologists,', 2.0), ('rightly', 2.0), ('Most', 2.0), ('countries', 2.0), ('declare', 2.0), ('understood', 2.0), ('dot', 2.0), ('allows', 2.0), ('paltry.', 2.0), ('who,', 2.0), ('of,', 2.0), ('wants', 2.0), ('innovations', 2.0), ('breakthroughs', 2.0), ('citrus', 2.0), ('strawberry', 2.0), ('farms.', 2.0), ('exclamation', 2.0), ('great', 2.0), ('inequity', 2.0), ('machine.', 2.0), ('reach', 2.0), ('buildings', 2.0), ('flying.', 2.0), ('depend', 2.0), ('smartphones,', 2.0), ('insist', 2.0), ('continuous', 2.0), ('improvement.', 2.0), ('2030.', 2.0), ('glass', 2.0), ('photographic', 2.0), ('plate.', 2.0), ('arrive', 2.0), ('solution.', 2.0), ('Electrification', 2.0), ('boundaries', 2.0), ('remember', 2.0), ('country', 2.0), ('health', 2.0), ('pressures', 2.0), ('intensify.', 2.0), ('First,', 2.0), ('are.', 2.0), ('citizenry', 2.0), ('operation,', 2.0), ('provide', 2.0), ('supply.', 2.0), ('photo', 2.0), ('weir', 2.0), ('devastating', 2.0), ('scene', 2.0), ('striving', 2.0), ('better.', 2.0), ('leaves', 2.0), ('room', 2.0), ('taught', 2.0), ('incredible', 2.0), ('might', 2.0), ('find', 2.0), ('such', 2.0), ('ones', 2.0), ('decide', 2.0), ('Ogochukwu', 2.0), ('her,', 2.0), ('effective', 2.0), ('achievable', 2.0), ('launched', 2.0), ('ocean’s', 2.0), ('biodiversity', 2.0), ('clean', 2.0), ('air:', 2.0), ('physical', 2.0), ('slower,', 2.0), ('SDG', 2.0), ('reporting', 2.0), ('managed', 2.0), ('grazing.', 2.0), ('discovering', 2.0), ('thousand', 2.0), ('supernovae', 2.0), ('bunch', 2.0), ('nature', 2.0), ('manner', 2.0), ('precision', 2.0), ('scale,', 2.0), ('collected,', 2.0), ('love', 2.0), ('medications,', 2.0), ('dosages', 2.0), ('deinvented.', 2.0), ('trucking', 2.0), ('waste.', 2.0), ('tubes', 2.0), ('congested', 2.0), ('hubs.', 2.0), ('oil', 2.0), ('embargo', 2.0), ('personally', 2.0), ('each', 2.0), ('level', 2.0), ('stage.', 2.0), ('poring', 2.0), ('night', 2.0), ('intersecting,', 2.0), ('converging.', 2.0), ('pigment-producing', 2.0), ('bacteria.', 2.0), ('produces', 2.0), (\"we've\", 2.0), ('done', 2.0), ('somebody', 2.0), ('say', 2.0), ('like,', 2.0), ('notion', 2.0), ('humans', 2.0), ('restore', 2.0), ('deploy', 2.0), ('sniper-like', 2.0), ('cars', 2.0), ('small', 2.0), ('Prius', 2.0), ('turn.', 2.0), ('discarded', 2.0), ('equipment', 2.0), ('Nestle', 2.0), ('van,', 2.0), ('Unilever', 2.0), ('largest', 2.0), ('lift', 2.0), ('benefit', 2.0), ('technologies,', 2.0), ('dozen,', 2.0), ('\"\"Stand', 2.0), ('aside,', 2.0), ('scientists,', 2.0), ('planetary', 2.0), ('one.', 2.0), (\"they're\", 2.0), ('layering', 2.0), ('web.', 2.0), ('effort,', 2.0), ('orbital', 2.0), ('chain', 2.0), ('privilege', 2.0), ('pioneering', 2.0), ('conserving', 2.0), ('land,', 2.0), ('education', 2.0), ('quickly,', 2.0), (\"he's\", 2.0), ('pass', 2.0), ('Although', 2.0), ('obviously', 2.0), ('nations', 2.0), ('shared', 2.0), ('sick', 2.0), ('patients', 2.0), ('analog', 2.0), ('quantum', 2.0), ('processor.', 2.0), ('diagnosing', 2.0), ('particular', 2.0), ('condition.', 2.0), ('sons', 2.0), ('professor', 2.0), ('herbicides', 2.0), ('never', 2.0), ('ceded,', 2.0), ('always', 2.0), ('sacred.', 2.0), ('lot', 2.0), ('individually', 2.0), ('determined', 2.0), ('retailers', 2.0), ('increase', 2.0), ('better,', 2.0), ('smarter', 2.0), ('recommend', 2.0), ('plans.', 2.0), ('leakage.', 2.0), ('caretaking', 2.0), ('is,', 2.0), ('applied', 2.0), ('distributed', 2.0), ('sources', 2.0), ('whose', 2.0), ('come.', 2.0), ('smelting,', 2.0), ('face', 2.0), ('existential', 2.0), ('risks', 2.0), ('replace', 2.0), ('brand', 2.0), ('borrow', 2.0), ('Getting', 2.0), ('ever', 2.0), ('cleaner', 2.0), ('electricity:', 2.0), ('synchronized', 2.0), ('foot', 2.0), ('glimpse', 2.0), ('visions', 2.0), ('flight,', 2.0), ('shaped', 2.0), ('series', 2.0), ('fishnets', 2.0), ('shut', 2.0), ('gave', 2.0), ('you,', 2.0), ('bought,', 2.0), ('sold,', 2.0), ('long', 2.0), ('From', 2.0), ('move', 2.0), ('either', 2.0), ('Because', 2.0), ('although', 2.0), ('spent', 2.0), ('show', 2.0), ('hire', 2.0), ('car', 2.0), ('ground', 2.0), ('up.', 2.0), ('excluding', 2.0), ('context?', 2.0), ('law,', 2.0), ('stores', 2.0), ('matter.', 2.0), ('least.', 2.0), ('marketers', 2.0), ('brands', 2.0), ('models', 2.0), ('usher', 2.0), ('solution', 2.0), ('headlines', 2.0), ('quasi-judicial', 2.0), ('process.', 2.0), ('basically', 2.0), ('unbanked', 2.0), ('underbanked,', 2.0), ('environmental', 2.0), ('itself.', 2.0), ('holistic', 2.0), ('overnight.', 2.0), ('engaged', 2.0), ('in.', 2.0), ('higher', 2.0), ('density.', 2.0), ('Moon', 2.0), ('1894', 2.0), ('slightly', 2.0), ('curved.', 2.0), ('own', 2.0), ('Milky', 2.0), ('Way.', 2.0), ('shine', 2.0), ('governed', 2.0), (\"Moore's\", 2.0), ('crops', 2.0), ('inside', 2.0), ('vertical', 2.0), ('farms', 2.0), ('two-seater', 2.0), ('prototype,', 2.0), ('fundamental', 2.0), ('drop-in', 2.0), ('replacements', 2.0), ('internal', 2.0), ('metagenomics', 2.0), ('gardening,', 2.0), ('incredibly', 2.0), ('powerful', 2.0), ('voice,', 2.0), ('focused', 2.0), ('purpose.', 2.0), ('saw,', 2.0), ('\"\"Wow,', 2.0), ('doable', 2.0), ('collected', 2.0), ('purposes', 2.0), ('hunger', 2.0), ('related', 2.0), ('COVID.', 2.0), ('received', 2.0), ('completed', 2.0), ('program,', 2.0), ('forces', 2.0), ('grew', 2.0), ('watching', 2.0), ('dioxide', 2.0), ('embedded', 2.0), ('happened', 2.0), ('nearby.', 2.0), ('low-risk', 2.0), ('areas.', 2.0), ('Aboriginals', 2.0), ('\"\"Can', 2.0), ('biotechnology', 2.0), ('samples', 2.0), ('gather,', 2.0), ('ceremonies,', 2.0), ('producing', 2.0), ('reusable', 2.0), ('dwell', 2.0), ('signal.', 2.0), ('grid', 2.0), ('zero-carbon', 2.0), ('rapidly', 2.0), ('traditional', 2.0), ('owners', 2.0), ('elders', 2.0), ('Way,', 2.0), ('Since', 2.0), ('census', 2.0), ('important,', 2.0), ('had', 1.96875), ('way.', 1.9375), ('very', 1.9375), ('our', 1.9082083702087402), (\"It's\", 1.82421875), ('those', 1.8125), ('are', 1.757965087890625), ('from', 1.75439453125), ('in', 1.751045435747193), ('can', 1.7509765625), ('take', 1.75), ('rural', 1.75), ('science,', 1.75), ('set', 1.75), ('global', 1.75), ('food', 1.75), ('down', 1.75), ('taken', 1.75), ('energy', 1.75), ('applying', 1.75), ('look', 1.75), ('so', 1.6923828125), ('will', 1.6875), ('by', 1.6455879211425781), ('how', 1.625), ('training', 1.625), ('some', 1.625), ('Think', 1.625), ('two', 1.625), ('has', 1.625), ('back', 1.625), ('around', 1.609375), ('really', 1.5625), ('up', 1.5625), (\"we're\", 1.5625), ('looking', 1.5625), ('there', 1.5625), ('out', 1.5625), ('this', 1.5371174812316895), ('for', 1.5332683324813843), ('all', 1.533203125), ('right', 1.53125), ('could', 1.53125), ('AI', 1.53125), ('actually', 1.53125), ('250', 1.5), ('do,', 1.5), ('studied', 1.5), ('talking', 1.5), ('amazing', 1.5), ('science', 1.5), ('your', 1.5), (\"it's\", 1.5), ('money,', 1.5), ('public', 1.5), ('then', 1.5), ('companies', 1.5), ('piece', 1.5), ('because', 1.5), ('range', 1.5), ('other', 1.5), ('seen', 1.5), ('computers', 1.5), ('save', 1.5), ('money', 1.5), ('along', 1.5), ('government', 1.5), ('well.', 1.5), ('There', 1.5), ('well,', 1.5), (\"We're\", 1.5), ('longer', 1.5), ('close', 1.5), ('create', 1.5), ('another', 1.5), ('tools', 1.5), ('challenges.', 1.5), ('One', 1.5), ('program', 1.5), ('described', 1.5), ('cost', 1.5), ('feel', 1.5), ('LO:', 1.5), ('pretty', 1.5), ('billion', 1.5), ('tons', 1.5), ('who', 1.5), ('something', 1.5), ('geographic', 1.5), ('today,', 1.5), ('others', 1.5), ('help', 1.5), ('simple', 1.5), ('telescope', 1.5), ('social', 1.5), ('already', 1.5), (\"didn't\", 1.5), ('carbon', 1.5), ('deserve', 1.5), ('astronomers', 1.5), ('doctors', 1.5), ('shows', 1.5), ('sort', 1.5), (\"He's\", 1.5), ('out,', 1.5), ('information.', 1.5), ('algorithms', 1.5), ('national', 1.5), ('issues,', 1.5), ('stay', 1.5), ('homes', 1.5), ('power', 1.5), ('second', 1.5), ('things,', 1.5), ('made', 1.5), ('than', 1.5), ('big', 1.5), ('performance', 1.5), ('solutions.', 1.5), ('society', 1.5), ('tech', 1.5), ('them,', 1.5), ('decisions', 1.5), ('database', 1.5), ('representative', 1.5), ('increasingly', 1.5), ('after', 1.5), ('wrong', 1.5), (\"We've\", 1.5), ('worldwide.', 1.5), ('supernova', 1.5), ('percent', 1.5), ('countries.', 1.5), ('together', 1.5), ('phenomenon,', 1.5), ('top', 1.5), ('crisis', 1.5), ('10', 1.5), ('mean', 1.5), ('there,', 1.5), ('time', 1.5), ('examples', 1.5), ('started', 1.5), ('Where', 1.5), ('they', 1.497802734375), ('is', 1.447512656494518), ('does', 1.4375), ('which', 1.416015625), ('like', 1.4145538806915283), ('just', 1.4140625), ('It', 1.40625), ('data', 1.390625), ('them', 1.3828125), ('JD:', 1.375), ('anything', 1.375), ('would', 1.375), ('go', 1.375), ('first', 1.375), ('you', 1.34796142578125), ('different', 1.34375), ('on', 1.3392252284102142), ('at', 1.33544921875), ('But', 1.328125), ('a', 1.321670849699701), ('when', 1.3125), ('more', 1.3125), ('get', 1.3125), ('have', 1.2926483154296875), (\"don't\", 1.28125), ('I', 1.2759409248828888), ('what', 1.273712158203125), ('think', 1.2734375), (\"that's\", 1.265625), ('we', 1.254038444487378), ('as', 1.251023292541504), ('large', 1.25), ('HH:', 1.25), ('know', 1.25), ('was', 1.25), ('building', 1.25), ('over', 1.25), ('coming', 1.25), ('systems', 1.25), ('relationship', 1.25), ('better', 1.25), ('my', 1.25), ('using', 1.25), ('technology', 1.25), ('deep', 1.25), ('You', 1.25), ('design', 1.25), ('three', 1.25), ('system', 1.25), ('same', 1.25), ('it.', 1.25), ('computer', 1.25), ('only', 1.25), ('world,', 1.25), ('live', 1.25), ('able', 1.25), ('should', 1.25), ('this.', 1.25), ('us', 1.234375), ('that', 1.2091128870898356), ('want', 1.203125), ('new', 1.19140625), ('make', 1.1875), ('much', 1.1875), ('and', 1.1728606850495185), ('now', 1.171875), ('the', 1.1601607940692706), ('The', 1.16015625), ('We', 1.1484375), ('into', 1.142578125), ('he', 1.125), ('been', 1.125), ('esports', 1.125), ('most', 1.125), ('you.', 1.125), ('—', 1.125), ('see', 1.125), ('being', 1.125), ('through', 1.125), ('it', 1.1095686294138432), ('In', 1.09375), ('people', 1.09375), ('things', 1.09375), ('were', 1.09375), ('to', 1.0900924115173898), ('their', 1.0869140625), ('So', 1.078155517578125), ('be', 1.0723423957824707), ('about', 1.07098388671875), ('these', 1.0679397583007812), ('if', 1.0625), ('even', 1.0625), ('me', 1.0625), ('use', 1.0625), ('doing', 1.0625), ('or', 1.0501569758635014), ('many', 1.046875), ('with', 1.039093017578125), ('need', 1.0390625), ('of', 1.0337543639436184), ('This', 1.03125), ('where', 1.02587890625), ('every', 1.00390625), ('do', 1.003173828125), ('And', 1.0000305634457618), ('environment', 1.0), ('climate', 1.0), ('decades', 1.0), ('before', 1.0), ('Tesla', 1.0), ('semitruck.', 1.0), ('understand', 1.0), ('exactly', 1.0), ('motivates', 1.0), ('sounds', 1.0), ('epic.', 1.0), ('Paris', 1.0), ('Accords', 1.0), ('individuals.', 1.0), ('meantime,', 1.0), ('air', 1.0), ('traffic', 1.0), ('controllers', 1.0), ('calculation', 1.0), ('simulation', 1.0), ('whole', 1.0), ('ways.', 1.0), ('thing', 1.0), ('extra', 1.0), ('training,', 1.0), ('four', 1.0), ('sectors', 1.0), ('economy.', 1.0), ('economy,', 1.0), ('infrastructure.', 1.0), ('galaxy.', 1.0), ('achieved', 1.0), ('climate.', 1.0), ('years,', 1.0), ('data.', 1.0), ('produce', 1.0), ('harvested,', 1.0), ('receiving', 1.0), ('Messi', 1.0), ('took', 1.0), ('home', 1.0), ('104', 1.0), ('million', 1.0), ('dollars.', 1.0), ('drug', 1.0), ('combat', 1.0), ('developed', 1.0), ('looked', 1.0), ('private', 1.0), ('sector,', 1.0), ('performance,', 1.0), ('real', 1.0), ('sport.', 1.0), ('central', 1.0), ('banks,', 1.0), ('universities,', 1.0), ('going', 1.0), ('prevent', 1.0), ('accidents', 1.0), ('possible.', 1.0), ('involves', 1.0), ('policy,', 1.0), ('obviously,', 1.0), ('Thanks,', 1.0), ('John.', 1.0), ('competition.', 1.0), ('organizations', 1.0), ('why', 1.0), ('current', 1.0), ('places,', 1.0), ('dominant', 1.0), ('Now,', 1.0), (\"aren't\", 1.0), ('yet', 1.0), ('do.', 1.0), ('you’re', 1.0), ('particularly', 1.0), ('excited', 1.0), ('about?', 1.0), ('nothing', 1.0), ('about,', 1.0), ('busy', 1.0), ('people.', 1.0), ('innovative', 1.0), ('city,', 1.0), ('China.', 1.0), ('industry.', 1.0), ('consumers', 1.0), ('absolutely', 1.0), ('case.', 1.0), ('observations', 1.0), ('regulated,', 1.0), ('digital', 1.0), ('platform', 1.0), ('food,', 1.0), ('student,', 1.0), ('got', 1.0), ('excited,', 1.0), ('world', 1.0), ('Sydney', 1.0), ('location', 1.0), ('way', 1.0), ('honestly,', 1.0), ('without', 1.0), ('that,', 1.0), ('If', 1.0), ('fail', 1.0), ('hit', 1.0), ('number,', 1.0), ('Right', 1.0), ('now,', 1.0), ('discover', 1.0), ('yours', 1.0), ('used,', 1.0), ('operator', 1.0), ('control', 1.0), ('dome.', 1.0), ('work', 1.0), ('hub', 1.0), ('human', 1.0), ('intervention,', 1.0), ('10,', 1.0), ('20', 1.0), ('years', 1.0), ('technology,', 1.0), ('understanding.\"\"', 1.0), ('access', 1.0), ('baked', 1.0), ('DNA.', 1.0), ('America’s', 1.0), ('electrification', 1.0), ('groups,', 1.0), ('environment.', 1.0), ('cursing', 1.0), ('saying,', 1.0), ('day,', 1.0), ('warning', 1.0), ('AI-driven', 1.0), ('systems.', 1.0), ('Your', 1.0), ('users', 1.0), ('making', 1.0), ('appearance', 1.0), ('electric', 1.0), ('vehicles', 1.0), ('universe,', 1.0), ('uses', 1.0), ('iterative', 1.0), ('approach', 1.0), ('used', 1.0), ('identify', 1.0), ('similarities', 1.0), ('geospatial', 1.0), ('nervous', 1.0), ('system.', 1.0), ('weaknesses', 1.0), (\"Doesn't\", 1.0), ('sound', 1.0), ('mechanical', 1.0), ('skill,', 1.0), ('sometimes', 1.0), ('taking', 1.0), ('theories', 1.0), ('idea', 1.0), ('not,', 1.0), ('let', 1.0), ('try', 1.0), (\"let's\", 1.0), ('clear', 1.0), ('...', 1.0), ('modular', 1.0), ('called', 1.0), ('PULSE,', 1.0), ('mammalian', 1.0), ('cells', 1.0), ('it’s', 1.0), ('international', 1.0), ('commitment.', 1.0), ('strikes', 1.0), ('Yeah.', 1.0), ('brilliant.', 1.0), ('dumping', 1.0), ('55', 1.0), ('TV', 1.0), ('reception', 1.0), ('antenna.', 1.0), ('ability', 1.0), ('advanced', 1.0), ('intersection', 1.0), (\"I'm\", 1.0), ('certain', 1.0), ('efficient', 1.0), ('me,', 1.0), (\"there's\", 1.0), ('Africa,', 1.0), ('India,', 1.0), ('Black', 1.0), (\"person's\", 1.0), ('image.', 1.0), ('one', 1.0), ('that’s', 1.0), ('based', 1.0), ('values', 1.0), ('answer', 1.0), ('simple:', 1.0), ('combining', 1.0), ('advances', 1.0), ('college', 1.0), ('degree,', 1.0), ('proprietary', 1.0), ('information', 1.0), ('US', 1.0), ('Environmental', 1.0), ('Protection', 1.0), ('Agency', 1.0), ('coal', 1.0), ('mine', 1.0), ('Is', 1.0), ('autonomous?', 1.0), ('None', 1.0), ('techniques', 1.0), ('He', 1.0), ('starting', 1.0), ('behind,', 1.0), ('enable', 1.0), ('sell', 1.0), ('add', 1.0), ('16', 1.0), ('trillion', 1.0), ('dollars', 1.0), ('Well,', 1.0), ('start', 1.0), ('stand.', 1.0), ('World', 1.0), ('Bank', 1.0), ('statistics,', 1.0), ('capital,', 1.0), ('medical', 1.0), ('images', 1.0), ('test', 1.0), ('results', 1.0), ('Imagine', 1.0), ('pandemic', 1.0), ('happens', 1.0), ('cash,', 1.0), ('serve', 1.0), ('multiple', 1.0), ('schools.', 1.0), ('advice', 1.0), ('zero', 1.0), ('benefits', 1.0), ('distributed,', 1.0), ('Plasma', 1.0), ('Science', 1.0), ('Fusion', 1.0), ('Centers', 1.0), ('discussion', 1.0), ('solutions', 1.0), ('talk', 1.0), ('little', 1.0), ('bit', 1.0), ('future', 1.0), ('security', 1.0), ('US.', 1.0), ('qualified', 1.0), ('job', 1.0), ('easy', 1.0), ('imaginations', 1.0), ('oldest', 1.0), ('third', 1.0), ('buildings.', 1.0), ('aviation,', 1.0), ('truth', 1.0), ('transformed', 1.0), ('country.', 1.0), ('removed', 1.0), ('However,', 1.0), ('camping', 1.0), ('labs', 1.0), ('mountains', 1.0), ('potatoes', 1.0), ('walking', 1.0), ('around,', 1.0), ('SR:', 1.0), ('transformation', 1.0), ('strategic', 1.0), ('Rule', 1.0), ('number', 1.0), ('four:', 1.0), ('locating', 1.0), ('store,', 1.0), ('progression,', 1.0), ('vote', 1.0), ('named', 1.0), ('Lionel', 1.0), ('Messi.', 1.0), ('play', 1.0), ('mechanically', 1.0), ('demanding', 1.0), ('nature.', 1.0), ('became', 1.0), ('her', 1.0), ('sisters', 1.0), ('mom', 1.0), (\"organizations'\", 1.0), ('while', 1.0), ('sense,', 1.0), ('business', 1.0), ('layers', 1.0), ('thank', 1.0), ('businesses', 1.0), ('society.', 1.0), ('All', 1.0), ('changes', 1.0), ('connect', 1.0), ('27-billion-dollar', 1.0), ('supports', 1.0), ('idealism,', 1.0), ('eliminating', 1.0), ('greenhouse', 1.0), ('gases', 1.0), ('Computers', 1.0), ('any', 1.0), ('organism', 1.0), ('helps', 1.0), ('up,', 1.0), ('going,', 1.0), ('interconnected', 1.0), ('camera', 1.0), ('Hispanic', 1.0), ('African', 1.0), ('workshopped', 1.0), ('planet.', 1.0), ('everybody,', 1.0), ('lone', 1.0), ('inventor', 1.0), ('skills', 1.0), ('respect.', 1.0), ('Plenty', 1.0), ('merging', 1.0), ('imagine', 1.0), ('begins', 1.0), ('asking', 1.0), ('care', 1.0), ('theorize', 1.0), ('invent.', 1.0), ('means', 1.0), ('effort', 1.0), ('especially', 1.0), ('Middle', 1.0), ('East', 1.0), ('problems.', 1.0), (\"everybody's\", 1.0), ('universe', 1.0), ('doubles', 1.0), ('does,', 1.0), ('LJ:', 1.0), ('emits', 1.0), ('dioxide.', 1.0), ('discovered', 1.0), ('powers,', 1.0), ('opposed', 1.0), (\"That's\", 1.0), ('possible', 1.0), ('yet,', 1.0), ('transformational,', 1.0), ('products', 1.0), ('everyday', 1.0), ('lives,', 1.0), ('scale', 1.0), ('convenience,', 1.0), ('design,', 1.0), ('build,', 1.0), ('regulate', 1.0), ('automation', 1.0), ('digitization', 1.0), ('opinion,', 1.0), ('realm', 1.0), ('policy.', 1.0), ('Australian', 1.0), ('Census', 1.0), ('2016', 1.0), ('looks', 1.0), ('secure', 1.0), ('required', 1.0), ('OMB', 1.0), ('individual', 1.0), ('programs', 1.0), ('dissipates.', 1.0), ('achieve', 1.0), ('revolution', 1.0), ('follow.', 1.0), ('electronic', 1.0), ('process,', 1.0), ('issue.', 1.0), ('important', 1.0), ('question', 1.0), ('all.', 1.0), ('literacy.', 1.0), ('telescope.', 1.0), ('investments.', 1.0), ('civilizations.', 1.0), ('integration', 1.0), ('coordinate', 1.0), ('spectacular', 1.0), ('miles', 1.0), ('behind', 1.0), ('everyone', 1.0), ('else.', 1.0), ('algorithm.', 1.0), ('essential', 1.0), ('StarCraft,', 1.0), ('various', 1.0), ('things.', 1.0), ('What', 1.0), ('fabric', 1.0), ('energy,', 1.0), ('ocean.', 1.0), ('largely', 1.0), ('meant', 1.0), ('entire', 1.0), ('enterprises.', 1.0), ('timing', 1.0), ('predict', 1.0), ('International', 1.0), (\"Children's\", 1.0), ('Summit.', 1.0), ('predictable.', 1.0), ('talked', 1.0), ('about.', 1.0), ('\"\"Us\"\"', 1.0), ('pointing', 1.0), ('river,', 1.0), ('15', 1.0), ('perfect', 1.0), ('example', 1.0), ('Then', 1.0), ('period', 1.0), ('time.', 1.0), ('appreciate', 1.0), ('teacher', 1.0), ('said?', 1.0), ('humanity’s', 1.0), ('artificial', 1.0), ('satellites', 1.0), ('build', 1.0), ('going.', 1.0), ('promised', 1.0), ('society,', 1.0), ('runs', 1.0), ('few', 1.0), ('hours', 1.0), ('drives', 1.0), ('day', 1.0), ('night.', 1.0), ('disruptions,', 1.0), ('Pretty', 1.0), ('idea.', 1.0), ('patch', 1.0), ('sky,', 1.0), ('now.', 1.0), ('fascinating', 1.0), ('two:', 1.0), ('smart', 1.0), ('cities', 1.0), ('know,', 1.0), ('town,', 1.0), ('doing,', 1.0), ('research', 1.0), ('development.', 1.0), ('aspect', 1.0), ('industrial', 1.0), ('evidence.', 1.0), ('counted,', 1.0), ('included,', 1.0), ('relatively', 1.0), ('often', 1.0), ('describes', 1.0), ('compare', 1.0), ('capabilities', 1.0), ('12-page', 1.0), ('legal', 1.0), ('agreement', 1.0), ('end', 1.0), ('absurd', 1.0), ('moments', 1.0), ('story.', 1.0), ('enough.', 1.0), ('days', 1.0), ('cooperatives,', 1.0), ('much,', 1.0), ('longer.\"\"', 1.0), ('transforming', 1.0), ('false', 1.0), ('choice.', 1.0), ('hardly', 1.0), ('changed', 1.0), ('1950s.', 1.0), ('exist', 1.0), ('time,', 1.0), ('\"\"Transformation', 1.0), ('change,', 1.0), ('futures.', 1.0), ('StarCraft', 1.0), ('Take', 1.0), ('2020', 1.0), ('Census.', 1.0), ('walk', 1.0), ('press', 1.0), ('button,', 1.0), ('digital-office', 1.0), ('environment,', 1.0), ('makes', 1.0), ('good', 1.0), ('policy?', 1.0), ('complicated', 1.0), ('plate', 1.0), ('Labour', 1.0), ('Organization,', 1.0), ('somewhere', 1.0), ('between', 1.0), ('understanding', 1.0), ('observations.', 1.0), ('usually', 1.0), ('fueled', 1.0), ('50', 1.0), ('change', 1.0), ('that.', 1.0), ('won', 1.0), ('art', 1.0), ('months', 1.0), ('Famous', 1.0), ('paid', 1.0), ('attention', 1.0), ('excelled.', 1.0), ('playing', 1.0), ('instrument', 1.0), ('piano.', 1.0), ('hope', 1.0), ('Lebanon', 1.0), ('takes', 1.0), ('2019,', 1.0), ('charge', 1.0), ('devices', 1.0), ('today?', 1.0), ('space', 1.0), ('locally', 1.0), ('available.', 1.0), ('ideas', 1.0), ('pure', 1.0), ('battery', 1.0), ('electric.', 1.0), ('high', 1.0), ('school', 1.0), ('orbiting', 1.0), ('planet', 1.0), ('centers', 1.0), ('schools,', 1.0), ('do.\"\"', 1.0), (\"can't\", 1.0), ('phone.', 1.0), ('With', 1.0), ('data,', 1.0), ('Without', 1.0), ('additional', 1.0), ('Open', 1.0), ('Bioeconomy', 1.0), ('Lab,', 1.0), ('may.', 1.0), ('weeks.', 1.0), (\"here's\", 1.0), ('shortcut.', 1.0), ('banking', 1.0), ('institution', 1.0), ('type.', 1.0), ('resources', 1.0), ('mention', 1.0), (\"Australia's\", 1.0), ('conversation', 1.0), ('someone', 1.0), ('help,', 1.0), ('exciting,', 1.0), ('internship,', 1.0), ('underwrite', 1.0), ('bank', 1.0), ('statistic', 1.0), ('we,', 1.0), ('humanity,', 1.0), ('last', 1.0), ('100', 1.0), ('years.', 1.0), ('including', 1.0), ('ending', 1.0), ('streets,', 1.0), ('life', 1.0), ('depends', 1.0), ('humans,', 1.0), ('value', 1.0), ('impact,', 1.0), ('working', 1.0), ('off', 1.0), ('instructions', 1.0), ('run', 1.0), ('bones', 1.0), ('biological', 1.0), ('designs.', 1.0), ('waiting', 1.0), ('airplane,', 1.0), ('house,', 1.0), ('instead,', 1.0), ('found', 1.0), ('did', 1.0), ('Of', 1.0), ('seven', 1.0), ('moment', 1.0), ('rest', 1.0), ('scientific', 1.0), ('questions', 1.0), ('founded', 1.0), ('3Ai', 1.0), ('Institute', 1.0), ('arts', 1.0), ('sciences', 1.0), ('education.', 1.0), ('working.', 1.0), ('India', 1.0), ('geopolitical', 1.0), ('inaction.', 1.0), ('theorizing', 1.0), ('existence,', 1.0), ('futures', 1.0), ('need.', 1.0), ('transform', 1.0), ('projects,', 1.0), ('observed', 1.0), ('printing,', 1.0), ('securing,', 1.0), ('turned', 1.0), ('supernova.', 1.0), ('Many', 1.0), ('daily', 1.0), ('inspire', 1.0), ('blended', 1.0), ('engineering', 1.0), ('narrative', 1.0), ('fifth', 1.0), ('you’d', 1.0), ('stepped', 1.0), ('several', 1.0), ('considered', 1.0), ('separate', 1.0), ('emissions', 1.0), ('role', 1.0), ('hostile', 1.0), ('attack.', 1.0), ('operated', 1.0), ('equally', 1.0), ('well', 1.0), ('intelligence.', 1.0), ('Yellow', 1.0), ('team', 1.0), ('Blue', 1.0), ('team.', 1.0), ('athlete', 1.0), ('places', 1.0), ('profound', 1.0), ('limitations', 1.0), ('candidate.', 1.0), ('attempt', 1.0), ('presents?', 1.0), ('unique', 1.0), ('expansive', 1.0), ('dialogues', 1.0), ('fourth', 1.0), ('phase', 1.0), ('initiatives.', 1.0), ('problems,', 1.0), ('skill', 1.0), ('master', 1.0), ('cheap,', 1.0), ('convenient', 1.0), ('easy.', 1.0), ('key', 1.0), ('live?', 1.0), ('its', 1.0), ('considering', 1.0), ('factors.', 1.0), ('compete', 1.0), ('gaming', 1.0), (\"isn't\", 1.0), ('history,', 1.0), ('rapid', 1.0), ('change.', 1.0), ('knowledge', 1.0), ('ideas?\"\"', 1.0), ('enterprise', 1.0), ('organization', 1.0), ('supporting', 1.0), ('impacts', 1.0), ('self-teaching', 1.0), ('programs.', 1.0), ('old', 1.0), ('ideas,', 1.0), ('edible', 1.0), ('insects', 1.0), ('strategies', 1.0), ('right.', 1.0), ('vulnerable.', 1.0), ('Bureau', 1.0), ('comes', 1.0), ('fair', 1.0), ('require', 1.0), ('Andromeda', 1.0), ('Nebula.', 1.0), ('European', 1.0), ('Union', 1.0), ('Mexico,', 1.0), ('United', 1.0), ('States.', 1.0), ('Can', 1.0), ('must,', 1.0), ('traffic,', 1.0), ('rules', 1.0), ('georeferencing,', 1.0), ('stands', 1.0), ('stage', 1.0), ('Australians,', 1.0), ('today.', 1.0), ('utility', 1.0), ('government.', 1.0), ('\"\"I', 1.0), ('collected,\"\"', 1.0), ('history', 1.0), ('local', 1.0), ('problems?\"\"', 1.0), ('AB:', 1.0), ('phone', 1.0), ('transformational', 1.0), (\"you've\", 1.0), ('implemented', 1.0), ('myself', 1.0), ('wife', 1.0), ('happening', 1.0), ('Small', 1.0), ('planes', 1.0), ('Ampaires', 1.0), ('promises', 1.0), ('biotechnology.', 1.0), ('active', 1.0), ('next.', 1.0), ('Addressing', 1.0), ('challenge', 1.0), ('Astronomers', 1.0), ('habit', 1.0), (\"them's\", 1.0), ('governor.', 1.0), ('credit', 1.0), ('recycled', 1.0), ('material.', 1.0), ('places.', 1.0), ('update.', 1.0), ('contributed', 1.0), ('others.', 1.0), ('direction.', 1.0), (\"world's\", 1.0), ('26', 1.0), ('per', 1.0), ('gallon.', 1.0), ('so,', 1.0), ('beings,', 1.0), ('admitting', 1.0), ('bugs', 1.0), ('area', 1.0), ('For', 1.0), ('example,', 1.0), ('urgently', 1.0), ('specific', 1.0), ('running', 1.0), ('independent', 1.0), ('went', 1.0), ('school,', 1.0), ('strategies.', 1.0), ('entrepreneur', 1.0), ('today', 1.0), ('Germans', 1.0), ('Chinese', 1.0), ('scientists', 1.0), ('WPR:', 1.0), ('point', 1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKj6eHlHYjHJ"
      },
      "source": [
        "A hipótese inicial, na qual era de que as palavras desconhecidas teriam maior nível, não é confirmada pela análise.\n",
        "\n",
        "Nota-se palavras como 'way', 'millions' e 'age', onde possuo conhecimento da semântica, mas a média está em 3.\n",
        "\n",
        "Portanto, verifica-se que somente com uma quantidade X de dados, muito maior que a quantidade atual, tal hipótese pode ser confirmada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujUy9T2mZRnF"
      },
      "source": [
        "# Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gcqlQEoglv"
      },
      "source": [
        "# Definição de variáveis\n",
        "\n",
        "vocab_size = 10000 # Tamanho do vocabulário\n",
        "embedding_dim = 16 # Número de dimensões da camada de embedding\n",
        "max_length = 100 # Maior tamanho das frases\n",
        "trunc_type = 'post' # Cortar ao final, caso a frase passa do tamanho estabelecido\n",
        "padding_type = 'post' # Cortar ao final, caso a frase não alcance o maior tamanho\n",
        "oov_tok = \"<OOV>\" # Adicionado em palavras fora do vocabulário"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh3vbP6kZVES"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU1JzB4VZYO_"
      },
      "source": [
        "# Importação\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OcinjvVZcbc"
      },
      "source": [
        "# Dividindo os dados em treino e testes\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRYoRffqZjrk"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=6000, oov_token=oov_tok)\n",
        "\n",
        "# Indexização das palavras\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "# Transformando a frase em uma lista de índices\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Transformando a lista de índices com todas do mesmo tamanho\n",
        "x_train = pad_sequences(x_train, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
        "x_test = pad_sequences(x_test, padding=padding_type, maxlen=max_length, truncating=trunc_type)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB0nEyv3Z8yS"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imiI55Cou7V4"
      },
      "source": [
        "O modelo construído possui como entrada a camada de Embedding, uma camada de ajustamento de tamanho da entrada, e duas camadas escondidas de 24 e 32 neurônios respectivamente, e 3 saídas, cada uma representando um tipo de dificuldade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNjR6kAXZ_0v"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BifTT9egaBRh"
      },
      "source": [
        "first_model = Sequential([\n",
        "  Embedding(vocab_size, embedding_dim,input_length=max_length),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(40, activation='relu'),\n",
        "  Dense(len(labels.columns), activation='softmax')\n",
        "])\n",
        "\n",
        "adam = Adam(learning_rate=0.05) # Otimizador que implementa o algoritmo de Adam\n",
        "\n",
        "first_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_aa2SkcaWrI",
        "outputId": "69b8bd92-f26d-4528-c73d-b4ca80871343"
      },
      "source": [
        "# Observando o modelo construído\n",
        "first_model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                2600      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 123       \n",
            "=================================================================\n",
            "Total params: 163,811\n",
            "Trainable params: 163,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPLatmrbaeFS"
      },
      "source": [
        "# Treinamento da rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oTd4qBMaree"
      },
      "source": [
        "### Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDjHaqnbakXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc93455-977c-40ac-8232-5054fd86e934"
      },
      "source": [
        "# Treinamento do modelo\n",
        "history = first_model.fit(x_train, y_train, batch_size=108,epochs=15, validation_split=0.25, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "5/5 [==============================] - 1s 44ms/step - loss: 0.6001 - accuracy: 0.5084 - val_loss: 0.5263 - val_accuracy: 0.5810\n",
            "Epoch 2/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5368 - accuracy: 0.6318 - val_loss: 0.5323 - val_accuracy: 0.5810\n",
            "Epoch 3/15\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.6318 - val_loss: 0.5240 - val_accuracy: 0.5810\n",
            "Epoch 4/15\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.6318 - val_loss: 0.5373 - val_accuracy: 0.5810\n",
            "Epoch 5/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.6318 - val_loss: 0.5333 - val_accuracy: 0.5810\n",
            "Epoch 6/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4736 - accuracy: 0.6318 - val_loss: 0.5251 - val_accuracy: 0.5810\n",
            "Epoch 7/15\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4012 - accuracy: 0.6318 - val_loss: 0.5622 - val_accuracy: 0.5754\n",
            "Epoch 8/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2879 - accuracy: 0.8393 - val_loss: 0.8931 - val_accuracy: 0.5810\n",
            "Epoch 9/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2394 - accuracy: 0.8561 - val_loss: 1.0712 - val_accuracy: 0.4693\n",
            "Epoch 10/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2220 - accuracy: 0.8598 - val_loss: 0.9710 - val_accuracy: 0.5028\n",
            "Epoch 11/15\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.8897 - val_loss: 1.0873 - val_accuracy: 0.6089\n",
            "Epoch 12/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.9121 - val_loss: 1.1698 - val_accuracy: 0.6257\n",
            "Epoch 13/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1332 - accuracy: 0.9178 - val_loss: 1.1080 - val_accuracy: 0.5531\n",
            "Epoch 14/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1227 - accuracy: 0.9140 - val_loss: 1.3368 - val_accuracy: 0.5922\n",
            "Epoch 15/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 0.9196 - val_loss: 1.3073 - val_accuracy: 0.6145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kYWy4tqdHv3"
      },
      "source": [
        "### Verificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JvfA18pdMUZ",
        "outputId": "db5a1a51-99eb-44d9-be98-a6b5b8f99fac"
      },
      "source": [
        "# Resultado dos parâmetros de acurácia e perda do modelo\n",
        "\n",
        "score = first_model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_pFHcQ-wDVh"
      },
      "source": [
        "### Conclusão\n",
        "\n",
        "A lógica da rede neural é coerente, entretanto, foi visto a falta de dados existente para a obtenção de uma classificação adequada. Com uma taxa de acurácia aproximada de 62% nos dados de treino, classifica-se o modelo como bom, mas não o ideal a ser aplicado, principalmente pela alta taxa de classificação como 'fácil'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtXn2SqxNGk4"
      },
      "source": [
        "# Classificando o resto das frases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5t_DyKvgNJ7X",
        "outputId": "fa7ec58d-d241-4489-9fe9-bb0e79f0c39a"
      },
      "source": [
        "# Operação para identificar qual o tipo de encodificação do arquivo\n",
        "with open('drive/MyDrive/Projetos/English/all_phrases.csv', 'rb') as f:\n",
        "    result = chardet.detect(f.read())\n",
        "\n",
        "# Lendo os dados e verificando as colunas visualmente\n",
        "all_data = pd.read_csv('drive/MyDrive/Projetos/English/all_phrases.csv', encoding=result['encoding'],quotechar='\"')\n",
        "all_data.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>phrase</th>\n",
              "      <th>document_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I work in aviation, but the truth is</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>I don't much like flying.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Current commercial flights</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>and use ancient plane designs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>that have hardly changed from the 1950s.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                    phrase  document_id\n",
              "0   1      I work in aviation, but the truth is            1\n",
              "1   2                 I don't much like flying.            1\n",
              "2   3                Current commercial flights            1\n",
              "3   6             and use ancient plane designs            1\n",
              "4   7  that have hardly changed from the 1950s.            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG-wVJW2N2Nq"
      },
      "source": [
        "# Eliminando as linhas vazias\n",
        "all_data = all_data.dropna()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GioAxSaNOWwk"
      },
      "source": [
        "x = []\n",
        "\n",
        "# Adequando as frases a um padrão\n",
        "for sentence in all_data['phrase'].values:\n",
        "  x.append(processing_text(sentence))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHBpH-rWOm4r"
      },
      "source": [
        "x = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "x = pad_sequences(x, padding=padding_type, maxlen=max_length, truncating=trunc_type)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20Qbn9ZO6YK",
        "outputId": "560d3b6b-eed0-424b-9918-9c888f772c91"
      },
      "source": [
        "all_predicteds = list()\n",
        "\n",
        "def index_of_max_value(array):\n",
        "  max_value = -1\n",
        "  ind = 0\n",
        "\n",
        "  for i, prob in enumerate(array):\n",
        "    if prob > max_value:\n",
        "      ind = i\n",
        "      max_value = prob\n",
        "\n",
        "  return ind\n",
        "\n",
        "for i, value in enumerate(x):\n",
        "  predicted = first_model.predict([value])[0]\n",
        "\n",
        "  level = index_of_max_value(predicted) + 1\n",
        "\n",
        "  all_predicteds.append(level)\n",
        "\n",
        "all_data['complexity'] = all_predicteds"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvFkpQarQXPB"
      },
      "source": [
        "import numpy as np\n",
        "# Normalizando o resultado\n",
        "\n",
        "comp_arr = np.array(all_data['complexity'].values)\n",
        "\n",
        "e = (comp_arr - comp_arr.min()) / (comp_arr.max() - comp_arr.min()) * 10\n",
        "\n",
        "all_data['normalize_complexity'] = e\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-f7Q_v4SwQK"
      },
      "source": [
        "json_file = all_data.to_json('phrases_with_complexity.json', orient='records')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMGxREIJz6RZ"
      },
      "source": [
        "### Conclusão\n",
        "\n",
        "O modelo condiz com a hipótese inicial: só funcionará em certos casos. A partir do treinamento, indaga-se que o modelo tende a classificar perto da média de dificuldade (0.5) nas predições, o que é ruim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz7E8-GpsZIT"
      },
      "source": [
        "# Tentativa de outro modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hO81LUtscyt"
      },
      "source": [
        "Pela primeira tentativa, com um modelo a partir da classificação das frases e suas dificuldades, a taxa de acerto foi bem baixa quando levada para os casos de teste. Portanto, agora o modelo será outro.\n",
        "\n",
        "A partir de uma base de dados de frequência de palavras, a rede neural irá receber como input a média da frequência das palavras da frase, e o output será o nível de dificuldade.\n",
        "\n",
        "Por hipótese inicial, a classificação será coerente somente em alguns casos, devido ao único valor de entrada ser a frequência."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXaYXqDrs7qg"
      },
      "source": [
        "### Importação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOL402Z3s7Ub"
      },
      "source": [
        "import urllib\n",
        "\n",
        "# Requisição do arquivo a partir da url\n",
        "url = 'https://raw.githubusercontent.com/hermitdave/FrequencyWords/master/content/2016/en/en_full.txt'\n",
        "file = urllib.request.urlopen(url)\n",
        "\n",
        "frequency_words = {}\n",
        "\n",
        "# Preenchendo o dicionário de frequência de palavras\n",
        "for line in file:\n",
        "  decoded_line = line.decode(\"utf-8\")\n",
        "  \n",
        "  word, frequency = decoded_line.split(' ')\n",
        "\n",
        "  frequency_words[word] = int(frequency.strip())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdky4q8PundL",
        "outputId": "39fd0c15-5195-4574-d5d4-2cef009c499a"
      },
      "source": [
        "# Teste\n",
        "frequency_words['hi']"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Q7nyxfvFrk"
      },
      "source": [
        "### Média das frequências nas frases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIpOPqdWvI2o"
      },
      "source": [
        "# Separando os dados de entrada e saída\n",
        "\n",
        "resources = data['phrase']\n",
        "labels = data['level']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBBZ_c7vZHD"
      },
      "source": [
        "# Calculando a média de frequência de cada frase\n",
        "x = []\n",
        "\n",
        "for sentence in resources:\n",
        "  sentence = processing_text(sentence)\n",
        "\n",
        "  mean = 0\n",
        "\n",
        "  split_sentence = sentence.split(' ')\n",
        "  size = len(split_sentence)\n",
        "\n",
        "  for word in split_sentence:\n",
        "    try:\n",
        "      # Realizando a raiz da frequência, para evitar grandes valores\n",
        "      mean += frequency_words[word]**0.5\n",
        "    except KeyError:\n",
        "      size -= 1\n",
        "\n",
        "  # Caso não tenha nenhuma palavra na sentença, a divisão será igual a 0.\n",
        "  # Portanto, a palavra é um número, cujo classificação é 'fácil'.\n",
        "  try:    \n",
        "    mean /= size\n",
        "  except ZeroDivisionError:\n",
        "    mean = max(x) \n",
        "\n",
        "  x.append(mean)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJEQTuHvxnz6"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dimensionando os dados os dados\n",
        "x = np.array(x).reshape(-1, 1)\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zgRaPco0H5L"
      },
      "source": [
        "# Redimensionando os valores de dificuldade\n",
        "y = labels.values / 3"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "869WoMcMx7ci"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VeflGNzPKc"
      },
      "source": [
        "Criando o modelo com uma camada de 8 neurônios e uma camada de saída com 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNY9VQt30FX8"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm1nRREU44Ng"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=[1]),\n",
        "    Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "optimizer = RMSprop(0.001) # Otimizador que implementa o algoritmo RMSprop\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=['mse'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHGpWsO65xWL",
        "outputId": "add2dff4-eab2-4458-8048-11e13b1999c4"
      },
      "source": [
        "model.fit(x=x_train, y=y_train, epochs=15, batch_size=32)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0443\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0430\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0425\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0425\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0423\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0423\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0422\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbfd64f0ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NPFDF0p7hXm"
      },
      "source": [
        "### Verificação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnrqABWG7gfY",
        "outputId": "9ebde986-fccc-4c77-e322-59a05622f75c"
      },
      "source": [
        "model.evaluate(x=x_test, y=y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - mse: 0.0434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.043379560112953186, 0.043379560112953186]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP2uy4Hj8jjy",
        "outputId": "0760f85b-ed05-4851-f8bc-421de72e3453"
      },
      "source": [
        "for i in range(3):\n",
        "  print(f'Predicted: {model.predict([x_test[i]])[0][0]}')\n",
        "  print(f'Real value: {y_test[i]}')\n",
        "  print()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 0.5025500655174255\n",
            "Real value: 0.3333333333333333\n",
            "\n",
            "Predicted: 0.44904011487960815\n",
            "Real value: 0.3333333333333333\n",
            "\n",
            "Predicted: 0.45005759596824646\n",
            "Real value: 0.6666666666666666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4uYDF3J0x5F"
      },
      "source": [
        "# Conclusão Geral\n",
        "\n",
        "A lógica dos dois modelos são coerentes, entretanto, devido a baixa quantidade de dados, não foi possível comprovar a viabilidade total do primeiro modelo, tendo em vista a taxa de acurácia ligada a grande classificação das frases como fáceis. Além disso, o segundo modelo pode ser utilizado, mas o resultado final deve ser remodelado para adequar aos reais níveis de complexidade.\n",
        "\n",
        "\n",
        "De tal forma, será utilizado o primeiro modelo, após uma maior classificação dos dados e assim a comprovação da hipótese de viabilidade."
      ]
    }
  ]
}